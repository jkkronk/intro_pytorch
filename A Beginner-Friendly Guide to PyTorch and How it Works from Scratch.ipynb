{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A Beginner-Friendly Guide to PyTorch and How it Works from Scratch "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Follow blog post here: https://www.analyticsvidhya.com/blog/2019/09/introduction-to-pytorch-from-scratch/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Download and install Pytorch from here: https://pytorch.org/get-started/locally/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's first import library "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Introduction to Tensors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pytorch tensors is very similar to numpy arrays. We initialize them as follows but can also use torch.ones(), torch.zeros() and random as shown below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch.Tensor'> \n",
      " tensor([[3, 3, 3],\n",
      "        [2, 2, 2],\n",
      "        [1, 1, 1]])\n"
     ]
    }
   ],
   "source": [
    "a = torch.tensor([[3,3,3],[2,2,2],[1,1,1]])\n",
    "print(type(a),'\\n', a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.]])\n"
     ]
    }
   ],
   "source": [
    "az = torch.zeros((3,3))\n",
    "print(az)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 1., 1.],\n",
      "        [1., 1., 1.],\n",
      "        [1., 1., 1.]])\n"
     ]
    }
   ],
   "source": [
    "ao = torch.ones((3,3))\n",
    "print(ao)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.3923, -0.2236, -0.3195],\n",
      "        [-1.2050,  1.0445, -0.6332],\n",
      "        [ 0.5731,  0.5409, -0.3919]])\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(2)\n",
    "ar = torch.randn(3,3)\n",
    "print(ar)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Matrix operations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Is done similarly to numpy. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ar+ao:  tensor([[ 1.3923,  0.7764,  0.6805],\n",
      "        [-0.2050,  2.0445,  0.3668],\n",
      "        [ 1.5731,  1.5409,  0.6081]])\n",
      "ar-ao:  tensor([[-0.6077, -1.2236, -1.3195],\n",
      "        [-2.2050,  0.0445, -1.6332],\n",
      "        [-0.4269, -0.4591, -1.3919]])\n",
      "ar*ao:  tensor([[-0.1508, -0.1508, -0.1508],\n",
      "        [-0.7938, -0.7938, -0.7938],\n",
      "        [ 0.7221,  0.7221,  0.7221]])\n",
      "ar/ao:  tensor([[ 0.3923, -0.2236, -0.3195],\n",
      "        [-1.2050,  1.0445, -0.6332],\n",
      "        [ 0.5731,  0.5409, -0.3919]])\n"
     ]
    }
   ],
   "source": [
    "print('ar+ao: ',torch.add(ar,ao))\n",
    "print('ar-ao: ',torch.sub(ar,ao))\n",
    "print('ar*ao: ',torch.mm(ar,ao))\n",
    "print('ar/ao: ',torch.div(ar,ao))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Transposing tensors</b>  is done with torch.t()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a = tensor([[3, 3, 3],\n",
      "        [2, 2, 2],\n",
      "        [1, 1, 1]])\n",
      "\n",
      " transpose(a) = \n",
      " tensor([[3, 2, 1],\n",
      "        [3, 2, 1],\n",
      "        [3, 2, 1]])\n"
     ]
    }
   ],
   "source": [
    "print('a =',a)\n",
    "at = torch.t(a)\n",
    "print('\\n transpose(a) = \\n', at)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use torch.cat((a,b)) to <b>Concatenting tensors </b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 1.],\n",
      "        [1., 1.],\n",
      "        [1., 1.],\n",
      "        [1., 1.]])\n"
     ]
    }
   ],
   "source": [
    "a = torch.ones((2,2))\n",
    "b = torch.ones((2,2))\n",
    "\n",
    "cat_ab = torch.cat((a,b))\n",
    "print(cat_ab)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use change dim if we want to concatenate the tensors horizontally. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1.]])\n"
     ]
    }
   ],
   "source": [
    "cat_ab = torch.cat((a,b), dim=1)\n",
    "print(cat_ab)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> Reshaping tensors </b>, similarly to numpy is done by .reshape() function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.6147, 0.3810, 0.6371],\n",
      "        [0.4745, 0.7136, 0.6190],\n",
      "        [0.4425, 0.0958, 0.6142]]) torch.Size([3, 3])\n",
      "tensor([[0.6147, 0.3810, 0.6371, 0.4745, 0.7136, 0.6190, 0.4425, 0.0958, 0.6142]]) torch.Size([1, 9])\n"
     ]
    }
   ],
   "source": [
    "# setting random seed\n",
    "torch.manual_seed(2)\n",
    "\n",
    "# init tensor\n",
    "a = torch.rand(3,3)\n",
    "print(a, a.shape)\n",
    "\n",
    "# reshaping tensor with .reshape()\n",
    "a_reshaped = a.reshape(1,9)\n",
    "print(a_reshaped, a_reshaped.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Common PyTorch Modules"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Autograd Module\n",
    "PyTorch uses a technique called automatic differentiation. It records all the operations that we are performing and replays it backward to compute gradients. This technique helps us to save time on each epoch as we are calculating the gradients on the forward pass itself."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# init tensor\n",
    "a = torch.ones((3,3), requires_grad=True)\n",
    "\n",
    "# perform operations\n",
    "b = a + 2\n",
    "c = b.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that c = sum(a+2)/9 and by manually calulate the gradients it would be 1/9=0.111... We verify this using pytorch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.1111, 0.1111, 0.1111],\n",
      "        [0.1111, 0.1111, 0.1111],\n",
      "        [0.1111, 0.1111, 0.1111]])\n"
     ]
    }
   ],
   "source": [
    "c.backward()\n",
    "print(a.grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Optim Module\n",
    "The Optim module in PyTorch has pre-written codes for most of the optimizers that are used while building a neural network. We just have to import them and then they can be used to build models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing the optim module\n",
    "from torch import optim\n",
    "\n",
    "# adam\n",
    "## adam = optim.Adam(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pytorch have support for most commonly used optimizers including: \n",
    " - SGD\n",
    " - ADAM\n",
    " - Adadelta\n",
    " - Adagrad\n",
    " - AdamW\n",
    " - SparseAdam\n",
    " - Adamax\n",
    " - RMSprop\n",
    " - And more..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building a Neural Network from Scratch in PyTorch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we init model parameters we need"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input tensor\n",
    "X = torch.Tensor([[1,0,1,0],[1,0,1,1],[0,1,0,1]])\n",
    "\n",
    "# output tensor \n",
    "y = torch.Tensor([[1],[1],[0]])\n",
    "\n",
    "# define activation function sigmoid and derivative of the \n",
    "# sigmoid for backpropagation\n",
    "def sigmoid(x):\n",
    "    return 1/(1 + torch.exp(-x))\n",
    "\n",
    "def der_sigmoid(x):\n",
    "    return x * (1-x)\n",
    "\n",
    "# init variables \n",
    "epoch = 7000\n",
    "lr_rate = 0.01\n",
    "X_neurons = X.shape[1] # nbr of features in data set\n",
    "hidden_neurons = 3 # nbr of hidden layers\n",
    "Y_neurons = 1 # nbr of output layers\n",
    "\n",
    "# init weights and bias, we randomly init weights and biases \n",
    "wh=torch.randn(X_neurons, hidden_neurons).type(torch.FloatTensor)\n",
    "bh=torch.randn(1, hidden_neurons).type(torch.FloatTensor)\n",
    "wout=torch.randn(hidden_neurons, Y_neurons)\n",
    "bout=torch.randn(1, Y_neurons)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we will create a neural network. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(epoch):\n",
    "    #Forward Propogation\n",
    "    hidden_layer_input1 = torch.mm(X, wh)\n",
    "    hidden_layer_input = hidden_layer_input1 + bh\n",
    "    hidden_layer_activations = sigmoid(hidden_layer_input)\n",
    "\n",
    "    output_layer_input1 = torch.mm(hidden_layer_activations, wout)\n",
    "    output_layer_input = output_layer_input1 + bout\n",
    "    output = sigmoid(output_layer_input)\n",
    "\n",
    "    #Backpropagation\n",
    "    E = y-output\n",
    "    slope_output_layer = der_sigmoid(output)\n",
    "    slope_hidden_layer = der_sigmoid(hidden_layer_activations)\n",
    "    d_output = E * slope_output_layer\n",
    "    Error_at_hidden_layer = torch.mm(d_output, wout.t())\n",
    "    d_hiddenlayer = Error_at_hidden_layer * slope_hidden_layer\n",
    "    wout += torch.mm(hidden_layer_activations.t(), d_output) *lr_rate\n",
    "    bout += d_output.sum() *lr_rate\n",
    "    wh += torch.mm(X.t(), d_hiddenlayer) *lr_rate\n",
    "    bh += d_output.sum() *lr_rate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Result of our network "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "actual :\n",
      " tensor([[1.],\n",
      "        [1.],\n",
      "        [0.]]) \n",
      "\n",
      "predicted :\n",
      " tensor([[0.9216],\n",
      "        [0.9177],\n",
      "        [0.1169]])\n"
     ]
    }
   ],
   "source": [
    "print('actual :\\n', y, '\\n')\n",
    "print('predicted :\\n', output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is how we can build and train a neural network from scratch in PyTorch. Let’s now take things up a notch and dive into a case study. We will try to solve that case study using the techniques we have learned in this article."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Solving an Image Classification Problem using PyTorch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our task is to identify the type of apparel by looking at a variety of apparel images. It’s a classic image classification problem using computer vision. This dataset, taken from the DataHack Platform, can be downloaded here: https://datahack.analyticsvidhya.com/contest/practice-problem-identify-the-apparels/?utm_source=blog&utm_medium=introduction-to-pytorch-from-scratch."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are 70,000 images, out of which 60,000 are in the training set and the remaining 10,000 in the test set. All the images are grayscale images of size (28*28).\n",
    "\n",
    "The dataset contains two folders – one each for the training set and the test set. In each folder, there is a .csv file that has the id of the image and its corresponding label and a folder containing the images for that particular set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading the data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing the libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from skimage.io import imread\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  label\n",
       "0   1      9\n",
       "1   2      0\n",
       "2   3      0\n",
       "3   4      3\n",
       "4   5      0"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# loading dataset\n",
    "train = pd.read_csv('train_LbELtWX/train.csv')\n",
    "test = pd.read_csv('test_ScVgIM0/test.csv')\n",
    "\n",
    "sample_submission = pd.read_csv('sample_submission_I5njJSF.csv')\n",
    "\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "'id' here represents the name of the image (we just have to add .png as the images are in png format) and 'label 'is the corresponding class of that particular image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# random number generator\n",
    "seed = 128\n",
    "rng = np.random.RandomState(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "51211\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1c22326710>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# print an image\n",
    "img_name = rng.choice(train['id']) # chooses a random image\n",
    "\n",
    "print(img_name)\n",
    "filepath = 'train_LbELtWX/train/' + str(img_name) + '.png'\n",
    "\n",
    "# read image and plot\n",
    "img = imread(filepath, as_gray=True)\n",
    "img = img.astype('float32')\n",
    "\n",
    "plt.figure(figsize=(5,5))\n",
    "plt.imshow(img, cmap='gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we will load all the training images using the train.csv file. We will use a for loop to read all the images from the training set and finally store them as a NumPy array:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28)\n"
     ]
    }
   ],
   "source": [
    "# loading training imgs\n",
    "train_img = np.zeros((np.count_nonzero(train['id']),28,28))\n",
    "\n",
    "# loop through every train img and load them to train_img numpy array\n",
    "for i, img_name in enumerate(train['id']):\n",
    "    img_path = 'train_LbELtWX/train/' + str(img_name) + '.png'\n",
    "    img = imread(img_path, as_gray=True)\n",
    "    img = img.astype('float32')\n",
    "    train_img[i,:,:] = img\n",
    "    \n",
    "train_x = np.array(train_img)\n",
    "print(train_x.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will be making a simple neural network which takes a one-dimensional input and hence we have to flatten these two-dimensional images into a single dimension:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 784)\n"
     ]
    }
   ],
   "source": [
    "train_x = train_x/train_x.max()\n",
    "train_x = train_x.reshape(-1, 28*28).astype('float32')\n",
    "print(train_x.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create target for training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_y = train['label'].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(((48600, 784), (48600,)), ((5400, 784), (5400,)))"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create validation set with train_test_split()\n",
    "train_x, val_x, train_y, val_y = train_test_split(train_x, train_y, test_size = 0.1, stratify = train_y)\n",
    "\n",
    "(train_x.shape, train_y.shape), (val_x.shape, val_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
